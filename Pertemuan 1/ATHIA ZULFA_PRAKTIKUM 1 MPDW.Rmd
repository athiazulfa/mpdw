---
title: "MPDW PRAKTIKUM 1"
author: "ATHIA ZULFA"
date: "2025-08-30"
output: html_document
---
```{r}
library("forecast")
library("graphics")
library("TTR")
library("TSA")
```
### *Import Data*
```{r}
library(rio)
data_mpdw <- import("https://raw.githubusercontent.com/gryoirsyad/mpdw/refs/heads/main/ice_cream.csv")
```
```{r}
data <- data_mpdw[346:460,]
data
```
```{r}
str(data)
dim(data)
```
```{r}
View(data)
```


```{r}
data.ts <- ts(data$IPN31152N)
```
### Uji Formal
```{r}
library(tseries)

# Augmented Dickey-Fuller Test
adf.test(data.ts)

# KPSS Test
kpss.test(data.ts)
```
ADF Test: p-value = 0.01 < 0.05 → tolak H0 non-stasioner → artinya data stasioner.
KPSS Test: p-value = 0.1 > 0.05 → gagal tolak H0 stasioner → artinya data stasioner.
Kesimpulan: Dari kedua tes tersebut, pola data konstan/stasioner, maka metode pemulusan yang tepat yaitu Single Exponential Smoothing (SES) atau Simple Moving Average (SMA).
```{r}
summary(data.ts)
```
```{r}
ts.plot(data.ts, xlab="Date ", ylab="Total Penjualan", 
        main = "Time Series Plot")
points(data.ts)
```

Menyimpan plot
```{r}
#menyimpan plot
#dev.copy(png, "eksplorasi.png")
#dev.off()
```
Pembagian data latih dan data uji dilakukan dengan perbandingan 80% data latih dan 20% data uji.
```{r}
#membagi data latih dan data uji
train <- data[1:92,]
test <- data[93:115,]
train.ts <- ts(train$IPN31152N)
test.ts <- ts(test$IPN31152N)
```

### Eksplorasi Data
Eksplorasi data dilakukan pada keseluruhan data, data latih serta data uji menggunakan plot data deret waktu.
```{r}
#eksplorasi keseluruhan data
plot(data.ts, col="red",main="Plot semua data")
points(data.ts)
```
```{r}
#eksplorasi data latih
plot(train.ts, col="blue",main="Plot data latih")
points(train.ts)
```

```{r}
#eksplorasi data uji
plot(test.ts, col="blue",main="Plot data uji")
points(test.ts)
```

Eksplorasi data juga dapat dilakukan menggunakan package `ggplot2` dengan terlebih dahulu memanggil library *package* `ggplot2`.

```{r}
# pastikan dulu Waktu sudah dalam format Date
train$DATE <- as.Date(train$DATE, format = "%Y-%m-%d")
test$DATE  <- as.Date(test$DATE,  format = "%Y-%m-%d")

```

```{r}
#Eksplorasi dengan GGPLOT
library(ggplot2)
ggplot() + 
  geom_line(data = train, aes(x = `DATE`, y = `IPN31152N`, col = "Data Latih")) +
  geom_line(data = test, aes(x = `DATE`, y = `IPN31152N`, col = "Data Uji")) +
  labs(x = "Date", y = "Total Penjualan", color = "Legend") +
  scale_colour_manual(name="Keterangan:", breaks = c("Data Latih", "Data Uji"),
                      values = c("blue", "red")) + 
  theme_bw() + theme(legend.position = "bottom",
                     plot.caption = element_text(hjust=0.5, size=12))
```

## *Single Moving Average (SMA)*

Ide dasar dari Single Moving Average (SMA) adalah data suatu periode dipengaruhi oleh data periode sebelumnya. Metode pemulusan ini cocok digunakan untuk pola data stasioner atau konstan. Prinsip dasar metode pemulusan ini adalah data pemulusan pada periode ke-t merupakan rata rata dari m buah data pada periode ke-t hingga periode ke (t-m+1). Data pemulusan pada periode ke-t selanjutnya digunakan sebagai nilai peramalan pada periode ke t+1

Pemulusan menggunakan metode SMA dilakukan dengan fungsi `SMA()`. Dalam hal ini akan dilakukan pemulusan dengan parameter `m=4`.
```{r}
data.sma<-SMA(train.ts, n=4)
data.sma
```
Data pemulusan pada periode ke-t selanjutnya digunakan sebagai nilai peramalan pada periode ke t+1 sehingga hasil peramalan 1 periode kedepan adalah sebagai berikut.
```{r}
data.ramal<-c(NA,data.sma)
data.ramal #forecast 1 periode ke depan
```
Selanjutnya akan dilakukan peramalan sejumlah data uji yaitu 23 periode. Pada metode SMA, hasil peramalan 23 periode ke depan akan bernilai sama dengan hasil peramalan 1 periode kedepan. Dalam hal ini akan dilakukan pengguabungan data aktual train, data hasil pemulusan dan data hasil ramalan 23 periode kedepan.

```{r}
data.gab<-cbind(
  aktual=c(data.ts),
  pemulusan=c(data.sma,rep(NA,23)),
  ramalan=c(data.ramal,rep(data.ramal[length(data.ramal)],22)))
```
```{r}
data.gab #forecast 23 periode ke depan
```
Adapun plot data deret waktu dari hasil peramalan yang dilakukan adalah sebagai berikut.

```{r}
ts.plot(data.ts, xlab="Date", ylab="Total Penjualan", main= "SMA N=4 Data Penjualan")
points(data.ts)
lines(data.gab[,2],col="green",lwd=2)
lines(data.gab[,3],col="red",lwd=2)
legend("topleft",c("data aktual","data pemulusan","data peramalan"), lty=8, col=c("black","green","red"), cex=0.5)
```

#### Menghitung nilai keakuratan data latih
```{r}
#Menghitung nilai keakuratan data latih
error_train.sma = train.ts-data.ramal[1:length(train.ts)]

SSE_train.sma = sum(error_train.sma[5:length(train.ts)]^2)
MSE_train.sma = mean(error_train.sma[5:length(train.ts)]^2)
MAPE_train.sma = mean(abs((error_train.sma[5:length(train.ts)]/train.ts[5:length(train.ts)])*100))

akurasi_train.sma <- matrix(c(SSE_train.sma, MSE_train.sma, MAPE_train.sma))
row.names(akurasi_train.sma)<- c("SSE", "MSE", "MAPE")
colnames(akurasi_train.sma) <- c("Akurasi m = 4")
akurasi_train.sma
```
MAPE data train pada metode pemulusan SMA sekitar 16%. Termasuk nilai akurasi cukup akurat.

#### Menghitung nilai keakuratan data uji

```{r}
# Ambil data aktual (baris 93-115, kolom 1)
actual_test <- data.gab[93:115, 1]

# Ambil data ramalan (baris 93-115, kolom 3)
forecast_test <- data.gab[93:115, 3]

# Hitung error
error_test.sma <- actual_test - forecast_test

# Hitung metrik
SSE_test.sma <- sum(error_test.sma^2)
MSE_test.sma <- mean(error_test.sma^2)
MAPE_test.sma <- mean(abs(error_test.sma / actual_test * 100))

# Simpan dalam matrix
akurasi_test.sma <- matrix(c(SSE_test.sma, MSE_test.sma, MAPE_test.sma))
row.names(akurasi_test.sma) <- c("SSE", "MSE", "MAPE")
colnames(akurasi_test.sma) <- c("Akurasi m = 4")

akurasi_test.sma
```
- Prediksi pada data testing lebih buruk dibanding training. MAPE pada data testing pada metode pemulusan SMA sekitar 22%. Termasuk nilai akurasi yang kurang akurat.
- SMA menghasilkan akurasi cukup baik untuk data training, tapi saat diuji pada data testing, error meningkat (MAPE naik dari 16% → 22%). Artinya, model stabil tapi tidak terlalu kuat untuk memprediksi data baru, bisa dikarenakan SMA tidak menangkap fluktuasi acak dengan baik.

## *Single Exponential Smoothing*

Metode *Exponential Smoothing* adalah metode pemulusan dengan melakukan pembobotan menurun secara eksponensial. Nilai yang lebih baru diberi bobot yang lebih besar dari nilai terdahulu. Terdapat satu atau lebih parameter pemulusan yang ditentukan secara eksplisit, dan hasil pemilihan parameter tersebut akan menentukan bobot yang akan diberikan pada nilai pengamatan. Ada dua macam model, yaitu model tunggal dan ganda. Single Exponential Smoothing merupakan metode pemulusan yang tepat digunakan untuk data dengan pola stasioner atau konstan.

Nilai pemulusan pada periode ke-t didapat dari persamaan:
$$
\tilde{y}_T=\lambda y_t+(1-\lambda)\tilde{y}_{T-1}
$$
Nilai parameter $\lambda$ adalah nilai antara 0 dan 1.

Nilai pemulusan periode ke-t bertindak sebagai nilai ramalan pada periode ke-$(T+\tau)$.

$$
\tilde{y}_{T+\tau}(T)=\tilde{y}_T
$$
Pembagian data latih dan data uji dilakukan dengan perbandingan 80% data latih dan 20% data uji.
```{r}
#membagi data latih dan data uji
train <- data[1:92,]
test <- data[93:115,]
train_ma.ts <- ts(train$IPN31152N)
test_ma.ts <- ts(test$IPN31152N)
```

Eksplorasi data dilakukan pada keseluruhan data, data latih serta data uji menggunakan plot data deret waktu.
```{r}
#eksplorasi keseluruhan data
plot(data.ts, col="red",main="Plot semua data")
points(data.ts)

#eksplorasi data latih
plot(train_ma.ts, col="blue",main="Plot data latih")
points(train_ma.ts)

#eksplorasi data uji
plot(test_ma.ts, col="blue",main="Plot data uji")
points(test_ma.ts)
```
```{r}
# pastikan dulu Waktu sudah Date
train$DATE <- as.Date(train$DATE, format = "%Y-%m-%d")
test$DATE  <- as.Date(test$DATE,  format = "%Y-%m-%d")
```
Eksplorasi data juga dapat dilakukan menggunakan package `ggplot2` .
```{r}
#Eksplorasi dengan GGPLOT
library(ggplot2)
ggplot() + 
  geom_line(data = train, aes(x = DATE, y = IPN31152N, col = "Data Latih")) +
  geom_line(data = test, aes(x = DATE, y = IPN31152N, col = "Data Uji")) +
  labs(x = "Date", y = "Total Penjualan", color = "Legend") +
  scale_colour_manual(name="Keterangan:", breaks = c("Data Latih", "Data Uji"),
                      values = c("blue", "red")) + 
  theme_bw() + theme(legend.position = "bottom",
                     plot.caption = element_text(hjust=0.5, size=12))
```

Pemulusan dengan metode SES dapat dilakukan dengan dua fungsi dari *packages* berbeda, yaitu (1) fungsi `ses()` dari *packages* `forecast` dan (2) fungsi `HoltWinters` dari *packages* `stats` .
```{r}
#Cara 1 (fungsi ses)
ses.1 <- ses(train.ts, h = 10, alpha = 0.2)
plot(ses.1)
ses.1

ses.2<- ses(train.ts, h = 10, alpha = 0.7)
plot(ses.2)
ses.2
```

Untuk mendapatkan gambar hasil pemulusan pada data latih dengan fungsi `ses()` , perlu digunakan fungsi `autoplot()` dan `autolayer()` dari *library packages* `ggplot2` .

```{r}
autoplot(ses.1) +
  autolayer(fitted(ses.1), series="Fitted") +
  ylab("Total Penjualan") + xlab("Date")
```
```{r}
#Cara 2 (fungsi Holtwinter)
ses1<- HoltWinters(train_ma.ts, gamma = FALSE, beta = FALSE, alpha = 0.2)
plot(ses1)

#ramalan
ramalan1<- forecast(ses1, h=10)
ramalan1

ses2<- HoltWinters(train_ma.ts, gamma = FALSE, beta = FALSE, alpha = 0.7)
plot(ses2)

#ramalan
ramalan2<- forecast(ses2, h=10)
ramalan2
```
Fungsi `HoltWinters` memiliki argumen yang sama dengan fungsi `ses()` . Argumen-argumen kedua fungsi dapat dilihat lebih lanjut dengan `?ses()` atau `?HoltWinters` .

Nilai parameter $\alpha$ dari kedua fungsi dapat dioptimalkan menyesuaikan dari *error*-nya paling minimumnya. Caranya adalah dengan membuat parameter $\alpha =$ `NULL` .
```{r}
#SES
ses.opt <- ses(train_ma.ts, h = 10, alpha = NULL)
plot(ses.opt)
ses.opt

#Lamda Optimum Holt Winter
HWopt<- HoltWinters(train_ma.ts, gamma = FALSE, beta = FALSE,alpha = NULL)
HWopt
plot(HWopt)

#ramalan
ramalanopt<- forecast(HWopt, h=10)
ramalanopt
```
Setelah dilakukan peramalan, akan dilakukan perhitungan keakuratan hasil peramalan. Perhitungan akurasi ini dilakukan baik pada data latih dan data uji.

#### Akurasi Data Latih
```{r}
#Keakuratan Metode
#Pada data training

# SES dengan alpha = 0.2
SSE1<-ses1$SSE
MSE1<-ses1$SSE/length(train_ma.ts)
RMSE1<-sqrt(MSE1)

akurasi1 <- matrix(c(SSE1,MSE1,RMSE1))
row.names(akurasi1)<- c("SSE", "MSE", "RMSE")
colnames(akurasi1) <- c("Akurasi lamda=0.2")
akurasi1
```

```{r}
# SES dengan alpha = 0.7
SSE2<-ses2$SSE
MSE2<-ses2$SSE/length(train_ma.ts)
RMSE2<-sqrt(MSE2)

akurasi2 <- matrix(c(SSE2,MSE2,RMSE2))
row.names(akurasi2)<- c("SSE", "MSE", "RMSE")
colnames(akurasi2) <- c("Akurasi lamda=0.7")
akurasi2
```
- Lamda 0.2: Error lebih tinggi (SSE, MSE, RMSE lebih besar), artinya model lebih lambat merespon perubahan data.
- Lamda 0.7: Error lebih rendah, artinya model lebih cepat menyesuaikan perubahan data.
- Dapat diambil kesimpulan: lambda 0.7 lebih baik untuk data training, karena menghasilkan kesalahan prediksi lebih kecil.

#### Akurasi Data Uji
```{r}
# jumlah observasi uji
n_test <- nrow(test)

# error (ramalan - aktual), samakan panjang dan tipe numeric
e1   <- as.numeric(ramalan1$mean)[1:n_test] - as.numeric(test$IPN31152N)
e2   <- as.numeric(ramalan2$mean)[1:n_test] - as.numeric(test$IPN31152N)
eopt <- as.numeric(ramalanopt$mean)[1:n_test] - as.numeric(test$IPN31152N)

# SSE / MSE / RMSE untuk masing-masing model (abaikan NA)
SSEtesting1  <- sum(e1^2,  na.rm = TRUE)
MSEtesting1  <- mean(e1^2, na.rm = TRUE)
RMSEtesting1 <- sqrt(MSEtesting1)

SSEtesting2  <- sum(e2^2,  na.rm = TRUE)
MSEtesting2  <- mean(e2^2, na.rm = TRUE)
RMSEtesting2 <- sqrt(MSEtesting2)

SSEtestingopt  <- sum(eopt^2,  na.rm = TRUE)
MSEtestingopt  <- mean(eopt^2, na.rm = TRUE)
RMSEtestingopt <- sqrt(MSEtestingopt)

# Tabel ringkas
akurasitesting_SSE <- matrix(c(SSEtesting1, SSEtesting2, SSEtestingopt),
                             nrow = 3,
                             dimnames = list(c("SSE1","SSE2","SSEopt"), "Nilai"))
akurasitesting_MSE <- matrix(c(MSEtesting1, MSEtesting2, MSEtestingopt),
                             nrow = 3,
                             dimnames = list(c("MSE1","MSE2","MSEopt"), "Nilai"))
akurasitesting_RMSE <- matrix(c(RMSEtesting1, RMSEtesting2, RMSEtestingopt),
                              nrow = 3,
                              dimnames = list(c("RMSE1","RMSE2","RMSEopt"), "Nilai"))

akurasitesting_SSE
```

```{r}
akurasitesting_MSE

```
```{r}
akurasitesting_RMSE

```
- SES1: RMSE = 27.56, error relatif lebih kecil daripada SES2/SESopt.
- SES2 / SESopt (lambda lebih besar atau parameter optimal lain): RMSE meningkat → prediksi lebih buruk di data testing.
- Dapat diambil kesimpulan: untuk data testing, SES dengan parameter tertentu (SES1) lebih stabil dibanding SES2/SESopt.
- Model yang terlalu cepat menyesuaikan perubahan (lambda besar) bisa overfit pada data training, sehingga prediksi di data testing kurang akurat.

## *Kesimpulan*
**1. SMA (m=4)**

Data Training:

- SSE = 54261.25 → total kesalahan kuadrat dari prediksi terhadap aktual cukup besar.
- MSE = 616.61 → rata-rata kesalahan kuadrat per titik data.
- MAPE = 16.18% → rata-rata persentase kesalahan relatif.

Data Testing:

- SSE = 19162.04 → lebih kecil daripada training (normal karena testing lebih sedikit).
- MSE = 833.13 → lebih besar dibanding training, artinya prediksi di testing sedikit kurang akurat.
- MAPE = 22.40% → kesalahan persentase lebih tinggi di testing.

Interpretasi SMA:

- SMA cukup akurat di training, tapi menurun saat testing.
- Kesalahan relatif cukup tinggi (MAPE > 20% di testing).

**2. SES (λ = 0.2 vs λ = 0.7)**

Data Training (λ = 0.2):

- SSE = 48546.77, MSE = 527.68, RMSE = 22.97 → dibanding SMA training → prediksi SES lebih akurat.

Data Training (λ = 0.7):

- SSE = 24628.03, MSE = 267.70, RMSE = 16.36 → jauh lebih baik daripada SMA dan SES λ=0.2 → SES lebih responsif dengan λ tinggi, menyesuaikan data terbaru.

Data Testing (nilai RMSE dan SSE):

- SSE1 = 7593.54, MSE2 = 1045.04, MSEopt = 1101.27
- RMSE1 = 27.56, RMSE2 = 32.33, RMSEopt = 33.19

Interpretasi SES:

- RMSE untuk data testing lebih tinggi dibanding training.
- Dibanding SMA testing, RMSE SES testing agak lebih besar (27.56–33.19 tergantung parameter), tapi SES lebih fleksibel karena λ tinggi lebih responsif terhadap perubahan data.

**3. Perbandingan SMA dengan SES**

- SES umumnya lebih akurat daripada SMA, terutama di data training dan saat menggunakan λ tinggi (lebih responsif).
- SMA cenderung lebih lambat merespons perubahan terbaru → MAPE testing lebih tinggi.

**4. Dari sudut pandang praktis**

- Pilih model yang memiliki RMSE terkecil di testing, karena ini menunjukkan seberapa akurat model memprediksi data baru. Meski model lain lebih akurat di training, itu belum tentu bagus untuk prakiraan nyata (bisa overfit). Jadi diambil dari model terbaik (SES λ=0,2) karena  dapat memperkirakan rata-rata error per prediksi sekitar 28 unit, sehingga lebih akurat dan dapat diandalkan untuk strategi penjualan eskrim. SMA masih bisa digunakan, tapi prediksinya kurang responsif terhadap perubahan tren penjualan terbaru, sehingga error bisa lebih besar lagi.
